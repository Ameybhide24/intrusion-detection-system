{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93I0Zdc8OCMd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "\n",
        "# 1. Load and preprocess dataset\n",
        "df = pd.read_csv(\"KDDTrain+.txt\", header=None)\n",
        "df_test = pd.read_csv(\"KDDTest+.txt\", header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT681eCPOl5j"
      },
      "outputs": [],
      "source": [
        "# Drop num_outbound_cmds (column 20)\n",
        "df.drop(columns=[20], inplace=True)\n",
        "df_test.drop(columns=[20], inplace=True)\n",
        "\n",
        "# One-hot encode protocol, service, flag (cols: 1, 2, 3)\n",
        "categorical_cols = [1, 2, 3]\n",
        "encoder = OneHotEncoder()\n",
        "encoded = encoder.fit_transform(df[categorical_cols]).toarray()\n",
        "encoded_test = encoder.transform(df_test[categorical_cols]).toarray()\n",
        "\n",
        "# Replace with numerical and drop original\n",
        "df_encoded = np.concatenate([encoded, df.drop(columns=categorical_cols).drop(columns=[41], axis=1).values], axis=1)\n",
        "df_test_encoded = np.concatenate([encoded_test, df_test.drop(columns=categorical_cols).drop(columns=[41], axis=1).values], axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0pQ71cEOpCB"
      },
      "outputs": [],
      "source": [
        "# Normalize\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(df_encoded)\n",
        "X_test = scaler.transform(df_test_encoded)\n",
        "\n",
        "# Binary labels\n",
        "y_train = df[41].apply(lambda x: 0 if x == 'normal' else 1).values\n",
        "y_test = df_test[41].apply(lambda x: 0 if x == 'normal' else 1).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUrzNzsKOru6",
        "outputId": "c830c0d7-3aad-40c7-da9c-ad7e7e4aae54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0492 - val_loss: 0.0353\n",
            "Epoch 2/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 0.0350 - val_loss: 0.0354\n",
            "Epoch 3/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0349 - val_loss: 0.0350\n",
            "Epoch 4/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0348 - val_loss: 0.0235\n",
            "Epoch 5/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0143 - val_loss: 0.0145\n",
            "Epoch 6/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0099 - val_loss: 0.0132\n",
            "Epoch 7/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0125\n",
            "Epoch 8/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0121\n",
            "Epoch 9/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0119\n",
            "Epoch 10/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0070 - val_loss: 0.0118\n",
            "Epoch 11/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0115\n",
            "Epoch 12/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0111\n",
            "Epoch 13/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0063 - val_loss: 0.0111\n",
            "Epoch 14/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0061 - val_loss: 0.0111\n",
            "Epoch 15/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0107\n",
            "Epoch 16/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 0.0108\n",
            "Epoch 17/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0106\n",
            "Epoch 18/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0105\n",
            "Epoch 19/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0105\n",
            "Epoch 20/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0104\n",
            "Epoch 21/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0057 - val_loss: 0.0104\n",
            "Epoch 22/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0120\n",
            "Epoch 23/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0103\n",
            "Epoch 24/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0105\n",
            "Epoch 25/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0100\n",
            "Epoch 26/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0102\n",
            "Epoch 27/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0099\n",
            "Epoch 28/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0099\n",
            "Epoch 29/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0100\n",
            "Epoch 30/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0102\n",
            "Epoch 31/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0099\n",
            "Epoch 32/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0098\n",
            "Epoch 33/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0102\n",
            "Epoch 34/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0097\n",
            "Epoch 35/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0101\n",
            "Epoch 36/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0098\n",
            "Epoch 37/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0108\n",
            "Epoch 38/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0098\n",
            "Epoch 39/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0099\n",
            "Epoch 40/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0100\n",
            "Epoch 41/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0101\n",
            "Epoch 42/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0098\n",
            "Epoch 43/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0097\n",
            "Epoch 44/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 45/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0098\n",
            "Epoch 46/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0094\n",
            "Epoch 47/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0094\n",
            "Epoch 48/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0093\n",
            "Epoch 49/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0092\n",
            "Epoch 50/50\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0094\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ccca516efd0>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 2. Build SSAE model\n",
        "def build_ssae():\n",
        "    inputs = tf.keras.Input(shape=(X_train.shape[1],))\n",
        "    encoded = tf.keras.layers.Dense(100, activation='sigmoid')(inputs)\n",
        "    encoded = tf.keras.layers.Dense(85, activation='sigmoid')(encoded)\n",
        "    encoded = tf.keras.layers.Dense(55, activation='sigmoid')(encoded)\n",
        "    bottleneck = tf.keras.layers.Dense(5, activation='sigmoid')(encoded)\n",
        "\n",
        "    decoded = tf.keras.layers.Dense(55, activation='sigmoid')(bottleneck)\n",
        "    decoded = tf.keras.layers.Dense(85, activation='sigmoid')(decoded)\n",
        "    decoded = tf.keras.layers.Dense(100, activation='sigmoid')(decoded)\n",
        "    outputs = tf.keras.layers.Dense(X_train.shape[1], activation='sigmoid')(decoded)\n",
        "\n",
        "    autoencoder = tf.keras.Model(inputs, outputs)\n",
        "    encoder_model = tf.keras.Model(inputs, bottleneck)\n",
        "\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "    return autoencoder, encoder_model\n",
        "\n",
        "autoencoder, encoder_model = build_ssae()\n",
        "autoencoder.fit(X_train, X_train, epochs=50, batch_size=128, validation_data=(X_test, X_test), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHMZke6TbmKG",
        "outputId": "d0cad9e4-5abf-4843-b1dd-52c1df4b136b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting 5-Fold Cross-Validation using SSAE+SVM (no data leakage)...\n",
            "\n",
            "\n",
            "--- Fold 1 ---\n",
            "\u001b[1m3150/3150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
            "\u001b[1m788/788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Fold 1 Accuracy: 0.8852\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8274    0.9922    0.9023     13469\n",
            "           1     0.9884    0.7622    0.8607     11726\n",
            "\n",
            "    accuracy                         0.8852     25195\n",
            "   macro avg     0.9079    0.8772    0.8815     25195\n",
            "weighted avg     0.9023    0.8852    0.8830     25195\n",
            "\n",
            "\n",
            "--- Fold 2 ---\n",
            "\u001b[1m3150/3150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
            "\u001b[1m788/788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Fold 2 Accuracy: 0.8829\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8245    0.9921    0.9006     13469\n",
            "           1     0.9881    0.7575    0.8575     11726\n",
            "\n",
            "    accuracy                         0.8829     25195\n",
            "   macro avg     0.9063    0.8748    0.8790     25195\n",
            "weighted avg     0.9006    0.8829    0.8805     25195\n",
            "\n",
            "\n",
            "--- Fold 3 ---\n",
            "\u001b[1m3150/3150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
            "\u001b[1m788/788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Fold 3 Accuracy: 0.8870\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8295    0.9926    0.9037     13469\n",
            "           1     0.9890    0.7656    0.8631     11726\n",
            "\n",
            "    accuracy                         0.8870     25195\n",
            "   macro avg     0.9092    0.8791    0.8834     25195\n",
            "weighted avg     0.9037    0.8870    0.8848     25195\n",
            "\n",
            "\n",
            "--- Fold 4 ---\n",
            "\u001b[1m3150/3150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
            "\u001b[1m788/788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Fold 4 Accuracy: 0.8824\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8245    0.9911    0.9001     13468\n",
            "           1     0.9867    0.7576    0.8571     11726\n",
            "\n",
            "    accuracy                         0.8824     25194\n",
            "   macro avg     0.9056    0.8744    0.8786     25194\n",
            "weighted avg     0.9000    0.8824    0.8801     25194\n",
            "\n",
            "\n",
            "--- Fold 5 ---\n",
            "\u001b[1m3150/3150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
            "\u001b[1m788/788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Fold 5 Accuracy: 0.8843\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8262    0.9924    0.9017     13468\n",
            "           1     0.9886    0.7602    0.8595     11726\n",
            "\n",
            "    accuracy                         0.8843     25194\n",
            "   macro avg     0.9074    0.8763    0.8806     25194\n",
            "weighted avg     0.9018    0.8843    0.8820     25194\n",
            "\n",
            "\n",
            "Average Cross-Validation Accuracy: 0.8843\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "\n",
        "# 5-Fold Cross-Validation (no leakage version)\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "acc_scores = []\n",
        "\n",
        "print(\"\\nStarting 5-Fold Cross-Validation using SSAE+SVM (no data leakage)...\\n\")\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n",
        "    print(f\"\\n--- Fold {fold} ---\")\n",
        "\n",
        "    # Raw split\n",
        "    X_fold_raw_train, X_fold_raw_val = X_train[train_idx], X_train[val_idx]\n",
        "    y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "    # OPTIONAL: Retrain the SSAE on the training fold if needed\n",
        "    # autoencoder.fit(X_fold_raw_train, X_fold_raw_train, epochs=..., batch_size=...)\n",
        "\n",
        "    # Encode the train and val sets using the pretrained SSAE\n",
        "    X_fold_train_encoded = encoder_model.predict(X_fold_raw_train)\n",
        "    X_fold_val_encoded = encoder_model.predict(X_fold_raw_val)\n",
        "\n",
        "    # SVM with class balancing\n",
        "    svm = SVC(kernel='rbf', C=10, gamma=0.01, class_weight='balanced')\n",
        "    svm.fit(X_fold_train_encoded, y_fold_train)\n",
        "    y_pred = svm.predict(X_fold_val_encoded)\n",
        "\n",
        "    # Evaluation\n",
        "    acc = accuracy_score(y_fold_val, y_pred)\n",
        "    acc_scores.append(acc)\n",
        "\n",
        "    print(f\"Fold {fold} Accuracy: {acc:.4f}\")\n",
        "    print(classification_report(y_fold_val, y_pred, digits=4))\n",
        "\n",
        "# Final average result\n",
        "print(\"\\nAverage Cross-Validation Accuracy: {:.4f}\".format(np.mean(acc_scores)))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}